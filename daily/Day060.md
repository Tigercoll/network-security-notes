---
title: Day060：内网基础 - 日志追踪与证据链
tags:
  - 网络
  - 安全
  - 学习计划
categories:
  - 网络安全
abbrlink: 8bafb6d4
date: 2026-02-22 00:00:00
updated: 2026-02-22 00:00:00

---
# Day060：内网基础 - 日志追踪与证据链

- 日期：2026-02-22
- 周次：第9周

## 学习目标

今天你将掌握日志追踪与证据链构建的核心知识：

- **理解日志分析**：掌握日志类型、来源和分析方法
- **构建时间线**：能根据多源日志构建攻击时间线
- **证据保全**：理解证据链的完整性和保全要求
- **关联分析**：能进行跨系统、跨日志源的关联分析
- **形成报告**：能编写清晰的事件调查报告

---

<!--more-->

## 学习内容

### 1️⃣ 日志分析基础

#### 1.1 日志类型与来源

```python
#!/usr/bin/env python3
"""
日志分析与证据链构建
"""
from __future__ import annotations
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Optional, list
import json


class LogType(Enum):
    """日志类型"""
    SECURITY = "安全日志"
    SYSTEM = "系统日志"
    APPLICATION = "应用日志"
    NETWORK = "网络日志"
    FIREWALL = "防火墙日志"
    DNS = "DNS 日志"
    WEB_SERVER = "Web 服务器日志"
    PROXY = "代理日志"
    EMAIL = "邮件日志"
    AUTHENTICATION = "认证日志"


class LogSeverity(Enum):
    """日志严重性"""
    CRITICAL = 5
    HIGH = 4
    MEDIUM = 3
    LOW = 2
    INFO = 1


@dataclass
class LogEntry:
    """日志条目"""
    log_id: str
    timestamp: datetime
    log_type: LogType
    source: str
    severity: LogSeverity
    event_type: str
    description: str
    source_ip: Optional[str] = None
    target_ip: Optional[str] = None
    username: Optional[str] = None
    process: Optional[str] = None
    raw_data: Optional[str] = None
    event_id: Optional[str] = None
    correlation_id: Optional[str] = None


@dataclass
class Evidence:
    """证据"""
    evidence_id: str
    type: str  # log, screenshot, memory_dump, pcap
    source: str
    timestamp: datetime
    hash_sha256: str
    description: str
    collected_by: str
    chain_of_custody: list[dict] = field(default_factory=list)
    integrity_verified: bool = False


class LogAnalyzer:
    """日志分析器"""
    
    # Windows 关键事件 ID
    WINDOWS_EVENTS = {
        "4624": {"name": "Successful Logon", "type": "Authentication"},
        "4625": {"name": "Failed Logon", "type": "Authentication"},
        "4648": {"name": "Explicit Credential Logon", "type": "Authentication"},
        "4672": {"name": "Special Privileges Assigned", "type": "Authorization"},
        "4673": {"name": "Sensitive Privilege Use", "type": "Authorization"},
        "4688": {"name": "Process Created", "type": "Process"},
        "4689": {"name": "Process Exited", "type": "Process"},
        "4697": {"name": "Service Installed", "type": "Service"},
        "4702": {"name": "Scheduled Task Created", "type": "Scheduled Task"},
        "4768": {"name": "TGT Requested", "type": "Kerberos"},
        "4769": {"name": "Service Ticket Requested", "type": "Kerberos"},
        "4771": {"name": "Kerberos Pre-auth Failed", "type": "Kerberos"},
        "5145": {"name": "Network Share Object Accessed", "type": "File Access"}
    }
    
    # Linux 关键日志位置
    LINUX_LOGS = {
        "/var/log/auth.log": {"type": LogType.AUTHENTICATION, "description": "认证日志"},
        "/var/log/syslog": {"type": LogType.SYSTEM, "description": "系统日志"},
        "/var/log/messages": {"type": LogType.SYSTEM, "description": "通用消息"},
        "/var/log/apache2/access.log": {"type": LogType.WEB_SERVER, "description": "Apache 访问日志"},
        "/var/log/apache2/error.log": {"type": LogType.WEB_SERVER, "description": "Apache 错误日志"},
        "/var/log/nginx/access.log": {"type": LogType.WEB_SERVER, "description": "Nginx 访问日志"},
        "/var/log/nginx/error.log": {"type": LogType.WEB_SERVER, "description": "Nginx 错误日志"},
        "/var/log/firewalld": {"type": LogType.FIREWALL, "description": "防火墙日志"},
        "/var/log/audit/audit.log": {"type": LogType.SECURITY, "description": "审计日志"},
        "/var/log/dns/bind.log": {"type": LogType.DNS, "description": "DNS 日志"}
    }
    
    def __init__(self):
        self.logs: list[LogEntry] = []
        self.evidence: list[Evidence] = []
    
    def add_log(self, log: LogEntry) -> None:
        """添加日志"""
        self.logs.append(log)
    
    def parse_windows_event(self, raw_line: str) -> Optional[LogEntry]:
        """解析 Windows 事件日志"""
        try:
            # 简化解析示例
            if "Event ID:" in raw_line:
                # 提取事件 ID
                event_id_start = raw_line.find("Event ID:") + len("Event ID:")
                event_id = raw_line[event_id_start:event_id_start+6].strip()
                
                # 提取时间
                timestamp_start = raw_line.find("Date:")
                timestamp_str = raw_line[timestamp_start+6:timestamp_start+30].strip()
                timestamp = datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")
                
                # 提取账户
                username_start = raw_line.find("Account:")
                username = ""
                if username_start != -1:
                    username_end = raw_line.find("\n", username_start)
                    username = raw_line[username_start+9:username_end].strip()
                
                # 提取源 IP
                ip_start = raw_line.find("Source Network Address:")
                source_ip = None
                if ip_start != -1:
                    ip_end = raw_line.find("\n", ip_start)
                    source_ip = raw_line[ip_start+24:ip_end].strip()
                
                event_info = self.WINDOWS_EVENTS.get(event_id, {"name": "Unknown", "type": "Other"})
                
                return LogEntry(
                    log_id=f"EVT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                    timestamp=timestamp,
                    log_type=LogType.SECURITY,
                    source="Windows Security Log",
                    severity=LogSeverity.INFO,
                    event_type=event_info["type"],
                    description=event_info["name"],
                    username=username if username else None,
                    source_ip=source_ip,
                    event_id=event_id
                )
        except Exception:
            pass
        return None
    
    def parse_syslog(self, raw_line: str) -> Optional[LogEntry]:
        """解析 Syslog"""
        try:
            # 标准 syslog 格式: <Month> <Day> <Time> <Host> <Process>[<PID>]: <Message>
            parts = raw_line.split(" ", 5)
            if len(parts) >= 6:
                month_map = {"Jan": 1, "Feb": 2, "Mar": 3, "Apr": 4, "May": 5, "Jun": 6,
                           "Jul": 7, "Aug": 8, "Sep": 9, "Oct": 10, "Nov": 11, "Dec": 12}
                
                month = month_map.get(parts[0], 1)
                day = int(parts[1])
                time_parts = parts[2].split(":")
                hour, minute, second = int(time_parts[0]), int(time_parts[1]), int(time_parts[2])
                year = datetime.now().year
                
                timestamp = datetime(year, month, day, hour, minute, second)
                hostname = parts[3]
                process_info = parts[4].strip()
                message = parts[5].strip() if len(parts) > 5 else ""
                
                # 确定日志类型和严重性
                log_type = LogType.SYSTEM
                severity = LogSeverity.INFO
                
                if "sshd" in process_info.lower():
                    log_type = LogType.AUTHENTICATION
                    severity = LogSeverity.INFO
                elif "sudo" in process_info.lower():
                    log_type = LogType.AUTHENTICATION
                    severity = LogSeverity.MEDIUM
                elif "failed" in message.lower():
                    severity = LogSeverity.LOW
                elif "error" in message.lower():
                    severity = LogSeverity.MEDIUM
                elif "critical" in message.lower():
                    severity = LogSeverity.CRITICAL
                
                return LogEntry(
                    log_id=f"SYS-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                    timestamp=timestamp,
                    log_type=log_type,
                    source=hostname,
                    severity=severity,
                    event_type="Process Event",
                    description=message[:100],
                    process=process_info
                )
        except Exception:
            pass
        return None
    
    def get_logs_by_timerange(
        self, 
        start: datetime, 
        end: Optional[datetime] = None
    ) -> list[LogEntry]:
        """按时间范围获取日志"""
        logs = [l for l in self.logs if l.timestamp >= start]
        if end:
            logs = [l for l in logs if l.timestamp <= end]
        return sorted(logs, key=lambda x: x.timestamp)
    
    def get_logs_by_username(self, username: str) -> list[LogEntry]:
        """按用户名获取日志"""
        return [l for l in self.logs if l.username and username.lower() in l.username.lower()]
    
    def get_logs_by_ip(self, ip: str) -> list[LogEntry]:
        """按 IP 地址获取日志"""
        return [l for l in self.logs if l.source_ip == ip or l.target_ip == ip]
    
    def get_logs_by_event_type(self, event_type: str) -> list[LogEntry]:
        """按事件类型获取日志"""
        return [l for l in self.logs if event_type.lower() in l.event_type.lower()]
```

#### 1.2 日志标准化

```python
#!/usr/bin/env python3
"""
日志标准化
"""
from __future__ import annotations
from dataclasses import dataclass
from datetime import datetime
from typing import Optional
import re


@dataclass
class NormalizedLog:
    """标准化日志"""
    original_id: str
    normalized_timestamp: datetime
    event_category: str
    event_name: str
    source_host: str
    source_ip: Optional[str]
    target_host: Optional[str]
    target_ip: Optional[str]
    username: Optional[str]
    action: str
    outcome: str  # Success, Failure, Unknown
    raw_message: str


class LogNormalizer:
    """日志标准化器"""
    
    # 时间格式映射
    TIME_FORMATS = [
        "%Y-%m-%d %H:%M:%S",
        "%Y/%m/%d %H:%M:%S",
        "%d/%b/%Y:%H:%M:%S %z",
        "%b %d %H:%M:%S",
        "%Y-%m-%dT%H:%M:%SZ",
        "%Y-%m-%dT%H:%M:%S.%fZ",
        "%d/%b/%Y %H:%M:%S"
    ]
    
    def normalize_timestamp(self, timestamp_str: str) -> Optional[datetime]:
        """标准化时间戳"""
        for fmt in self.TIME_FORMATS:
            try:
                return datetime.strptime(timestamp_str, fmt)
            except ValueError:
                continue
        return None
    
    def normalize_ip(self, ip: str) -> Optional[str]:
        """标准化 IP 地址"""
        if not ip:
            return None
        
        # 清理 IPv6 括号
        ip = ip.strip().strip("[]")
        
        # 验证 IP 格式
        ipv4_pattern = r'^(\d{1,3}\.){3}\d{1,3}$'
        if re.match(ipv4_pattern, ip):
            return ip
        
        return ip
    
    def normalize_log(self, raw_log: dict) -> NormalizedLog:
        """标准化日志"""
        return NormalizedLog(
            original_id=raw_log.get("id", ""),
            normalized_timestamp=self.normalize_timestamp(
                raw_log.get("timestamp", "")
            ) or datetime.now(),
            event_category=raw_log.get("category", "Unknown"),
            event_name=raw_log.get("event", "Unknown"),
            source_host=raw_log.get("source_host", ""),
            source_ip=self.normalize_ip(raw_log.get("source_ip")),
            target_host=raw_log.get("target_host", ""),
            target_ip=self.normalize_ip(raw_log.get("target_ip")),
            username=raw_log.get("username"),
            action=raw_log.get("action", "Unknown"),
            outcome=raw_log.get("outcome", "Unknown"),
            raw_message=raw_log.get("raw_message", "")
        )
    
    def export_to_json(self, logs: list[NormalizedLog], filename: str) -> None:
        """导出标准化日志"""
        import json
        data = [
            {
                "id": log.original_id,
                "timestamp": log.normalized_timestamp.isoformat(),
                "category": log.event_category,
                "event": log.event_name,
                "source_host": log.source_host,
                "source_ip": log.source_ip,
                "target_host": log.target_host,
                "target_ip": log.target_ip,
                "username": log.username,
                "action": log.action,
                "outcome": log.outcome
            }
            for log in logs
        ]
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
```

---

### 2️⃣ 时间线构建

#### 2.1 时间线分析

```python
#!/usr/bin/env python3
"""
时间线构建与分析
"""
from __future__ import annotations
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional, list


@dataclass
class TimelineEvent:
    """时间线事件"""
    event_id: str
    timestamp: datetime
    event_type: str
    description: str
    source: str
    severity: str  # Critical, High, Medium, Low
    actor: Optional[str] = None
    target: Optional[str] = None
    evidence_ids: list[str] = field(default_factory=list)
    notes: str = ""


class TimelineBuilder:
    """时间线构建器"""
    
    def __init__(self):
        self.events: list[TimelineEvent] = []
    
    def add_event(self, event: TimelineEvent) -> None:
        """添加事件"""
        self.events.append(event)
    
    def add_log_event(
        self,
        timestamp: datetime,
        event_type: str,
        description: str,
        source: str,
        severity: str,
        **kwargs
    ) -> str:
        """从日志添加事件"""
        import uuid
        event_id = f"EVT-{uuid.uuid4().hex[:8]}"
        
        event = TimelineEvent(
            event_id=event_id,
            timestamp=timestamp,
            event_type=event_type,
            description=description,
            source=source,
            severity=severity,
            actor=kwargs.get("username"),
            target=kwargs.get("target"),
            evidence_ids=kwargs.get("evidence_ids", []),
            notes=kwargs.get("notes", "")
        )
        
        self.events.append(event)
        return event_id
    
    def build_timeline(
        self, 
        start: datetime, 
        end: datetime
    ) -> list[TimelineEvent]:
        """构建时间范围的时间线"""
        timeline = [
            e for e in self.events 
            if start <= e.timestamp <= end
        ]
        return sorted(timeline, key=lambda x: x.timestamp)
    
    def categorize_events(self) -> dict:
        """按类别分类事件"""
        categories = {}
        for event in self.events:
            if event.event_type not in categories:
                categories[event.event_type] = []
            categories[event.event_type].append(event)
        return categories
    
    def get_critical_events(self) -> list[TimelineEvent]:
        """获取关键事件"""
        return [e for e in self.events if e.severity in ["Critical", "High"]]
    
    def get_events_by_actor(self, actor: str) -> list[TimelineEvent]:
        """按执行者获取事件"""
        return [e for e in self.events if e.actor and actor.lower() in e.actor.lower()]
    
    def generate_timeline_report(self, start: datetime, end: datetime) -> str:
        """生成时间线报告"""
        timeline = self.build_timeline(start, end)
        
        report = f"""# 事件时间线报告

## 报告信息
- **时间范围**: {start.strftime('%Y-%m-%d %H:%M:%S')} 至 {end.strftime('%Y-%m-%d %H:%M:%S')}
- **事件总数**: {len(timeline)}
- **关键事件**: {len(self.get_critical_events())}

## 时间线详情

| 时间 | 类型 | 严重性 | 描述 | 执行者 | 来源 |
|------|------|--------|------|--------|------|
"""
        
        for event in timeline:
            report += f"| {event.timestamp.strftime('%Y-%m-%d %H:%M:%S')} | "
            report += f"{event.event_type} | "
            report += f"{event.severity} | "
            report += f"{event.description[:50]}... | "
            report += f"{event.actor or '-'} | "
            report += f"{event.source} |\n"
        
        # 按类别统计
        categories = self.categorize_events()
        report += "\n## 按类别统计\n\n"
        report += "| 类别 | 事件数 |\n"
        report += "|-------|--------|\n"
        for category, events in categories.items():
            report += f"| {category} | {len(events)} |\n"
        
        return report
    
    def export_timeline_csv(self, filename: str) -> None:
        """导出时间线为 CSV"""
        import csv
        
        with open(filename, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                "Event ID", "Timestamp", "Event Type", "Severity",
                "Description", "Actor", "Target", "Source", "Notes"
            ])
            
            for event in sorted(self.events, key=lambda x: x.timestamp):
                writer.writerow([
                    event.event_id,
                    event.timestamp.isoformat(),
                    event.event_type,
                    event.severity,
                    event.description,
                    event.actor or "",
                    event.target or "",
                    event.source,
                    event.notes
                ])
```

---

### 3️⃣ 证据链管理

#### 3.1 证据收集与保全

```python
#!/usr/bin/env python3
"""
证据链管理
"""
from __future__ import annotations
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional
import hashlib
import json


@dataclass
class EvidenceItem:
    """证据项"""
    evidence_id: str
    type: str  # log, screenshot, memory_dump, pcap, file
    source: str
    description: str
    collected_at: datetime
    collected_by: str
    hash_sha256: str
    size_bytes: int
    storage_location: str
    chain_of_custody: list[dict] = field(default_factory=list)
    integrity_verified: bool = False
    verified_at: Optional[datetime] = None


class EvidenceChainManager:
    """证据链管理器"""
    
    def __init__(self):
        self.evidence_items: list[EvidenceItem] = []
    
    def calculate_hash(self, file_path: str) -> str:
        """计算文件 SHA256 哈希"""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256_hash.update(chunk)
        return sha256_hash.hexdigest()
    
    def add_evidence(
        self,
        evidence_type: str,
        source: str,
        description: str,
        collected_by: str,
        file_path: Optional[str] = None,
        storage_location: str = "/evidence"
    ) -> EvidenceItem:
        """添加证据"""
        import uuid
        
        if file_path:
            hash_value = self.calculate_hash(file_path)
            size_bytes = len(open(file_path, 'rb').read())
        else:
            hash_value = ""
            size_bytes = 0
        
        evidence = EvidenceItem(
            evidence_id=f"EV-{uuid.uuid4().hex[:12].upper()}",
            type=evidence_type,
            source=source,
            description=description,
            collected_at=datetime.now(),
            collected_by=collected_by,
            hash_sha256=hash_value,
            size_bytes=size_bytes,
            storage_location=storage_location,
            chain_of_custody=[
                {
                    "action": "Collected",
                    "timestamp": datetime.now().isoformat(),
                    "person": collected_by,
                    "location": storage_location
                }
            ]
        )
        
        self.evidence_items.append(evidence)
        return evidence
    
    def verify_integrity(self, evidence_id: str) -> bool:
        """验证证据完整性"""
        for evidence in self.evidence_items:
            if evidence.evidence_id == evidence_id:
                if evidence.hash_sha256:
                    current_hash = self.calculate_hash(evidence.storage_location)
                    if current_hash == evidence.hash_sha256:
                        evidence.integrity_verified = True
                        evidence.verified_at = datetime.now()
                        return True
        return False
    
    def update_chain_of_custody(
        self, 
        evidence_id: str, 
        action: str, 
        person: str,
        location: str
    ) -> None:
        """更新证据链"""
        for evidence in self.evidence_items:
            if evidence.evidence_id == evidence_id:
                evidence.chain_of_custody.append({
                    "action": action,
                    "timestamp": datetime.now().isoformat(),
                    "person": person,
                    "location": location
                })
                break
    
    def generate_evidence_report(self) -> str:
        """生成证据报告"""
        report = """# 证据清单报告

## 证据概览

| 证据ID | 类型 | 来源 | 收集时间 | 完整性 |
|--------|------|------|----------|--------|
"""
        
        for evidence in self.evidence_items:
            status = "✓ 已验证" if evidence.integrity_verified else "✗ 未验证"
            report += f"| {evidence.evidence_id} | "
            report += f"{evidence.type} | "
            report += f"{evidence.source} | "
            report += f"{evidence.collected_at.strftime('%Y-%m-%d %H:%M')} | "
            report += f"{status} |\n"
        
        # 证据链详情
        report += "\n## 证据链详情\n\n"
        
        for evidence in self.evidence_items:
            report += f"### {evidence.evidence_id}: {evidence.description}\n\n"
            report += f"- **类型**: {evidence.type}\n"
            report += f"- **来源**: {evidence.source}\n"
            report += f"- **收集人**: {evidence.collected_by}\n"
            report += f"- **收集时间**: {evidence.collected_at.isoformat()}\n"
            report += f"- **哈希**: {evidence.hash_sha256}\n"
            report += f"- **大小**: {evidence.size_bytes} 字节\n"
            report += f"- **存储位置**: {evidence.storage_location}\n\n"
            
            report += "**证据链**:\n"
            for entry in evidence.chain_of_custody:
                report += f"- [{entry['timestamp']}] {entry['action']} by {entry['person']} at {entry['location']}\n"
            
            report += "\n---\n\n"
        
        return report
    
    def export_evidence_manifest(self, filename: str) -> None:
        """导出证据清单"""
        manifest = {
            "generated_at": datetime.now().isoformat(),
            "total_items": len(self.evidence_items),
            "verified_items": sum(1 for e in self.evidence_items if e.integrity_verified),
            "evidence": [
                {
                    "id": e.evidence_id,
                    "type": e.type,
                    "source": e.source,
                    "description": e.description,
                    "collected_at": e.collected_at.isoformat(),
                    "collected_by": e.collected_by,
                    "hash": e.hash_sha256,
                    "integrity_verified": e.integrity_verified
                }
                for e in self.evidence_items
            ]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(manifest, f, indent=2, ensure_ascii=False)
```

---

### 4️⃣ 关联分析与报告

#### 4.1 跨日志源关联

```python
#!/usr/bin/env python3
"""
跨日志源关联分析
"""
from __future__ import annotations
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Optional, List


@dataclass
class Correlation:
    """关联分析结果"""
    correlation_id: str
    correlation_type: str
    description: str
    confidence: float  # 0-1
    related_logs: List[dict]
    attack_stage: str
    recommendation: str


class LogCorrelator:
    """日志关联分析器"""
    
    def __init__(self):
        self.correlations: list[Correlation] = []
    
    def correlate_by_timestamp(
        self,
        logs1: list,
        logs2: list,
        time_window: int = 60  # 秒
    ) -> list:
        """按时间关联两个日志源"""
        matches = []
        
        for log1 in logs1:
            log1_time = log1.get("timestamp", datetime.min)
            
            for log2 in logs2:
                log2_time = log2.get("timestamp", datetime.min)
                
                time_diff = abs((log1_time - log2_time).total_seconds())
                if time_diff <= time_window:
                    matches.append({
                        "log1": log1,
                        "log2": log2,
                        "time_difference": time_diff
                    })
        
        return matches
    
    def correlate_by_ip(self, logs: list) -> dict:
        """按 IP 地址关联日志"""
        ip_logs = {}
        
        for log in logs:
            source_ip = log.get("source_ip")
            target_ip = log.get("target_ip")
            
            for ip in [source_ip, target_ip]:
                if ip:
                    if ip not in ip_logs:
                        ip_logs[ip] = []
                    ip_logs[ip].append(log)
        
        return ip_logs
    
    def correlate_by_username(self, logs: list) -> dict:
        """按用户名关联日志"""
        user_logs = {}
        
        for log in logs:
            username = log.get("username")
            if username:
                if username not in user_logs:
                    user_logs[username] = []
                user_logs[username].append(log)
        
        return user_logs
    
    def detect_attack_pattern(
        self,
        logs: list,
        pattern: str
    ) -> list[Correlation]:
        """检测攻击模式"""
        correlations = []
        
        if pattern == "brute_force":
            # 检测暴力破解
            user_logs = self.correlate_by_username(logs)
            for username, user_log_list in user_logs.items():
                failed_logs = [
                    l for l in user_log_list 
                    if l.get("outcome") == "Failure"
                ]
                if len(failed_logs) >= 5:
                    correlations.append(Correlation(
                        correlation_id=f"BR-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                        correlation_type="Brute Force Attack",
                        description=f"用户 {username} 检测到 {len(failed_logs)} 次失败登录尝试",
                        confidence=0.85,
                        related_logs=failed_logs,
                        attack_stage="Initial Access",
                        recommendation="审查账户安全，启用账户锁定策略"
                    ))
        
        elif pattern == "lateral_movement":
            # 检测横向移动
            ip_logs = self.correlate_by_ip(logs)
            for ip, ip_log_list in ip_logs.items():
                network_logs = [
                    l for l in ip_log_list 
                    if l.get("event_type") in ["SMB", "RDP", "WMI"]
                ]
                if len(network_logs) >= 3:
                    correlations.append(Correlation(
                        correlation_id=f"LM-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                        correlation_type="Potential Lateral Movement",
                        description=f"从 {ip} 检测到多次远程访问尝试",
                        confidence=0.75,
                        related_logs=network_logs,
                        attack_stage="Lateral Movement",
                        recommendation="审查网络访问日志，确认是否为授权行为"
                    ))
        
        elif pattern == "privilege_escalation":
            # 检测权限提升
            priv_logs = [
                l for l in logs
                if "4672" in str(l.get("event_id", "")) or
                   "sudo" in str(l.get("process", "")).lower()
            ]
            if priv_logs:
                correlations.append(Correlation(
                    correlation_id=f"PE-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                    correlation_type="Privilege Escalation",
                    description=f"检测到 {len(priv_logs)} 次权限提升事件",
                    confidence=0.90,
                    related_logs=priv_logs,
                    attack_stage="Privilege Escalation",
                    recommendation="审查权限变更，确认是否为授权操作"
                ))
        
        self.correlations.extend(correlations)
        return correlations
    
    def generate_investigation_report(self) -> str:
        """生成调查报告"""
        report = """# 安全事件调查报告

## 调查概览

"""
        
        # 统计
        total_correlations = len(self.correlations)
        critical_correlations = [c for c in self.correlations if c.confidence >= 0.8]
        
        report += f"- **关联分析总数**: {total_correlations}\n"
        report += f"- **高置信度关联**: {len(critical_correlations)}\n"
        report += f"- **报告生成时间**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        
        # 按攻击阶段分组
        by_stage = {}
        for corr in self.correlations:
            if corr.attack_stage not in by_stage:
                by_stage[corr.attack_stage] = []
            by_stage[corr.attack_stage].append(corr)
        
        report += "\n## 按攻击阶段分析\n\n"
        
        for stage, corrs in by_stage.items():
            report += f"### {stage} ({len(corrs)} 个关联)\n\n"
            
            for corr in corrs:
                report += f"#### {corr.correlation_type}\n"
                report += f"- **置信度**: {corr.confidence * 100:.0f}%\n"
                report += f"- **描述**: {corr.description}\n"
                report += f"- **建议**: {corr.recommendation}\n"
                report += f"- **相关日志数**: {len(corr.related_logs)}\n\n"
        
        # 时间线摘要
        report += "\n## 关键发现时间线\n\n"
        
        all_timestamps = []
        for corr in self.correlations:
            for log in corr.related_logs:
                if "timestamp" in log:
                    all_timestamps.append(log["timestamp"])
        
        all_timestamps = sorted(set(all_timestamps))
        
        if all_timestamps:
            report += f"- **最早事件**: {min(all_timestamps).strftime('%Y-%m-%d %H:%M:%S')}\n"
            report += f"- **最晚事件**: {max(all_timestamps).strftime('%Y-%m-%d %H:%M:%S')}\n"
            report += f"- **时间跨度**: {(max(all_timestamps) - min(all_timestamps)).total_seconds() / 3600:.1f} 小时\n"
        
        return report
```

---

## 实践任务（合法授权范围内）

> **注意**：以下任务请在你自己的测试环境、虚拟机或授权靶场中执行。

---

### 任务 1（必做）：日志收集与分析

**目标**：收集多源日志并进行分析。

**步骤**：

```powershell
# PowerShell - Windows 日志收集

# 1. 收集安全日志
Get-WinEvent -LogName Security -MaxEvents 1000 | 
    Export-Csv -Path "security_events.csv" -NoTypeInformation

# 2. 收集系统日志
Get-WinEvent -LogName System -MaxEvents 500 | 
    Export-Csv -Path "system_events.csv" -NoTypeInformation

# 3. 收集应用日志（示例）
Get-WinEvent -LogName Application -MaxEvents 500 | 
    Export-Csv -Path "application_events.csv" -NoTypeInformation

# 4. 收集特定事件
$events = Get-WinEvent -LogName Security -FilterXPath "*[System[EventID=4624]]"
$events | Export-Csv -Path "logon_events.csv" -NoTypeInformation
```

---

### 任务 2（必做）：构建时间线

**目标**：根据日志构建攻击时间线。

**步骤**：

```python
#!/usr/bin/env python3

from timeline_builder import TimelineBuilder
from log_analyzer import LogAnalyzer
from datetime import datetime, timedelta

# 1. 创建时间线构建器
timeline = TimelineBuilder()

# 2. 添加关键事件
timeline.add_log_event(
    timestamp=datetime(2024, 1, 15, 10, 0, 0),
    event_type="Initial Access",
    description="首次检测到来自 192.168.1.100 的登录尝试",
    source="Firewall",
    severity="Medium",
    username="admin"
)

timeline.add_log_event(
    timestamp=datetime(2024, 1, 15, 10, 5, 0),
    event_type="Authentication",
    description="成功登录，用户 admin",
    source="Windows Security Log",
    severity="Info",
    username="admin",
    target="DC01.corp.local"
)

timeline.add_log_event(
    timestamp=datetime(2024, 1, 15, 10, 15, 0),
    event_type="Privilege Escalation",
    description="检测到特权分配事件 4672",
    source="Windows Security Log",
    severity="High",
    username="admin"
)

# 3. 生成时间线报告
start = datetime(2024, 1, 15, 9, 0, 0)
end = datetime(2024, 1, 15, 12, 0, 0)

report = timeline.generate_timeline_report(start, end)
print(report)

# 4. 导出时间线
timeline.export_timeline_csv("timeline_export.csv")
```

---

### 任务 3（必做）：证据链管理

**目标**：建立证据收集和保管流程。

**步骤**：

```python
#!/usr/bin/env python3

from evidence_chain_manager import EvidenceChainManager
from datetime import datetime

# 1. 创建证据链管理器
ecm = EvidenceChainManager()

# 2. 添加证据
evidence1 = ecm.add_evidence(
    evidence_type="log",
    source="Windows Security Log",
    description="登录事件日志",
    collected_by="Analyst",
    storage_location="/evidence/logs/login_events.evtx"
)

evidence2 = ecm.add_evidence(
    evidence_type="screenshot",
    source="SIEM Dashboard",
    description="攻击告警截图",
    collected_by="Analyst",
    storage_location="/evidence/screenshots/alert_001.png"
)

# 3. 验证证据完整性
is_valid = ecm.verify_integrity(evidence1.evidence_id)
print(f"证据完整性验证: {is_valid}")

# 4. 更新证据链
ecm.update_chain_of_custody(
    evidence1.evidence_id,
    action="Analyzed",
    person="Forensic Analyst",
    location="/analysis/working"
)

# 5. 生成证据报告
report = ecm.generate_evidence_report()
print(report)

# 6. 导出证据清单
ecm.export_evidence_manifest("evidence_manifest.json")
```

---

### 任务 4（必做）：关联分析

**目标**：进行跨日志源的关联分析。

**步骤**：

```python
#!/usr/bin/env python3

from log_correlator import LogCorrelator

# 1. 创建关联分析器
correlator = LogCorrelator()

# 2. 示例日志数据
logs = [
    {"timestamp": datetime(2024, 1, 15, 10, 0, 0), "event_type": "Firewall", "outcome": "Blocked", "source_ip": "192.168.1.100"},
    {"timestamp": datetime(2024, 1, 15, 10, 1, 0), "event_type": "Authentication", "outcome": "Failure", "username": "admin", "source_ip": "192.168.1.100"},
    {"timestamp": datetime(2024, 1, 15, 10, 2, 0), "event_type": "Authentication", "outcome": "Failure", "username": "admin", "source_ip": "192.168.1.100"},
    {"timestamp": datetime(2024, 1, 15, 10, 3, 0), "event_type": "Authentication", "outcome": "Success", "username": "admin", "source_ip": "192.168.1.100"},
    {"timestamp": datetime(2024, 1, 15, 10, 5, 0), "event_type": "SMB", "outcome": "Success", "username": "admin", "target_ip": "192.168.1.200"},
    {"timestamp": datetime(2024, 1, 15, 10, 10, 0), "event_type": "Process", "event_id": "4688", "username": "admin"},
]

# 3. 检测暴力破解
brute_force = correlator.detect_attack_pattern(logs, "brute_force")
for corr in brute_force:
    print(f"[{corr.correlation_type}] {corr.description}")

# 4. 检测横向移动
lateral = correlator.detect_attack_pattern(logs, "lateral_movement")
for corr in lateral:
    print(f"[{corr.correlation_type}] {corr.description}")

# 5. 生成调查报告
report = correlator.generate_investigation_report()
print(report)
```

---

## 巩固练习（题与复盘）

---

### 练习 1：证据链完整性

**问题**：如何避免证据链断裂？

**思路提示**：

| 环节 | 防护措施 |
|------|----------|
| **收集** | 记录时间、收集人、位置，使用哈希验证 |
| **存储** | 限制访问，副本备份，写入保护 |
| **传输** | 加密传输，校验完整性 |
| **分析** | 只读副本，工具验证，记录所有操作 |
| **归档** | 标准格式，长期保存，可检索 |

---

### 练习 2：日志字段要求

**问题**：设计日志应包含的字段要求。

**示例答案**：

```python
# 必需日志字段
REQUIRED_LOG_FIELDS = {
    "时间戳": {
        "required": True,
        "format": "ISO 8601",
        "example": "2024-01-15T10:30:00Z"
    },
    "事件类型": {
        "required": True,
        "values": ["Authentication", "Authorization", "Network", "Process", "File"]
    },
    "源地址": {
        "required": True,
        "format": "IPv4/IPv6"
    },
    "目标地址": {
        "required": False,
        "format": "IPv4/IPv6"
    },
    "用户标识": {
        "required": True,
        "format": "字符串"
    },
    "结果": {
        "required": True,
        "values": ["Success", "Failure", "Unknown"]
    },
    "事件ID": {
        "required": False,
        "format": "Windows Event ID 或 Syslog Tag"
    },
    "描述": {
        "required": True,
        "format": "可读文本，描述事件详情"
    }
}
```

---

### 练习 3：调查最佳实践

**问题**：有效的事件调查最佳实践是什么？

**示例答案**：

```python
# 事件调查最佳实践
INVESTIGATION_BEST_PRACTICES = {
    "准备阶段": [
        "建立调查预案和角色分工",
        "准备调查工具和存储介质",
        "确认证据收集权限和法律依据"
    ],
    "收集阶段": [
        "优先收集易失性证据（内存、网络连接）",
        "按顺序收集证据（内存 → 网络 → 磁盘）",
        "记录所有操作和发现"
    ],
    "分析阶段": [
        "建立时间线，确定攻击序列",
        "关联多源日志，验证假设",
        "识别攻击者手法和影响范围"
    ],
    "报告阶段": [
        "客观记录发现，避免猜测",
        "提供时间线和证据链",
        "给出修复建议和预防措施"
    ],
    "复盘阶段": [
        "总结经验教训",
        "更新检测规则",
        "改进防御措施"
    ]
}
```

---

## 评估标准（达成判定）

- ✅ 能收集和解析多源日志
- ✅ 能构建事件时间线
- ✅ 能管理证据链的完整性和可追溯性
- ✅ 能进行跨日志源的关联分析
- ✅ 能编写清晰的事件调查报告

---

## 学习成果达成情况（由学习者填写）

### 截图与证据

- [ ] 日志收集截图
- [ ] 时间线构建截图
- [ ] 证据链管理截图
- [ ] 调查报告截图

### 关键命令与输出

**日志收集**：
```powershell
Get-WinEvent -LogName Security -MaxEvents 1000 | Export-Csv security_events.csv
```

**时间线导出**：
```bash
$ python3 timeline_builder.py
[+] 时间线报告已生成
[+] 导出文件: timeline_export.csv
[+] 总事件: 25个
```

### 结论与反思

**我今天搞清楚了**：

- 不同类型日志的来源和解析方法
- 时间线构建的关键要素和技巧
- 证据链管理的完整性和法律要求
- 跨日志源关联分析的方法
- 事件调查报告的编写规范

**我差点搞混的是**：

- 不同时间格式的解析方法
- 证据链和证据完整性的区别
- 关联分析和模式检测的关系

**明天我要继续补的是**：

- 高级持续威胁（APT）检测
- 云安全监控
- 自动化响应

**本次学习耗时**：约 4 小时

**掌握程度自评**：

- [ ] 😕 理解了基本概念，但实践不熟练
- [ ] 🙂 完成了基础任务
- [ ] 😃 完成了所有任务并理解原理
- [ ] 🤩 额外建立了完整的事件调查工作流


## 学习成果示例填写（可照抄）

> 可将"示例"内容替换为你自己的时间与截图文件名。

### 截图与证据（示例）

- 任务 1：`images/dayXXX_task1.png`

### 关键命令与输出（示例）

```
命令示例：
输出示例：
```

### 结论与反思（示例）

**我今天搞清楚了**：
- （示例）理解了核心概念

**我差点搞混的是**：
- （示例）某个易混淆点

**明天我要继续补的是**：
- （示例）下一步深入方向

**本次学习耗时**：约 2 小时

**掌握程度自评**：
- [x] 😃 完成了所有任务并理解原理
