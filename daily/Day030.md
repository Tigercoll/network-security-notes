---
title: Day030：日志与可观测性 - 收集与传输：Syslog/Filebeat 入门
tags:
  - 网络
  - 安全
  - 学习计划
categories:
  - 网络安全
abbrlink: 3c549a29
date: 2026-01-23 00:00:00
updated: 2026-01-23 00:00:00

---
# Day030：日志与可观测性 - 收集与传输：Syslog/Filebeat 入门

- 日期：2026-01-23
- 周次：第5周

## 学习目标

今天你将掌握日志收集与传输的基础知识：

- **理解日志收集链路**：从日志产生到集中存储的完整流程
- **掌握 Syslog 协议**：理解 Syslog 的消息格式和传输方式
- **学会 Filebeat 配置**：能配置 Filebeat 采集本地日志并转发
- **了解缓冲与重试**：理解数据传输失败时的处理策略
- **实现基础过滤**：能在传输阶段对日志进行简单过滤

---

<!--more-->

## 学习内容

### 1️⃣ 日志收集与传输链路

#### 1.1 完整链路架构

```
日志收集与传输链路
│
├─ [日志源] ──────┐
│  ├─ 系统日志      │
│  ├─ 应用日志      │
│  ├─ 服务日志      │
│  └─ 安全日志      │
│                  │
│                  ▼
│             [采集层]
│  ┌───────────────────────┐
│  │ Filebeat / Fluentd    │
│  │ Logstash             │
│  └───────────────────────┘
│                  │
│                  ▼
│             [传输层]
│  ┌───────────────────────┐
│  │ Syslog (UDP/TCP)     │
│  │ HTTP/HTTPS          │
│  │ Kafka               │
│  └───────────────────────┘
│                  │
│                  ▼
│            [缓冲层]
│  ┌───────────────────────┐
│  │ Kafka / Redis       │
│  │ RabbitMQ            │
│  └───────────────────────┘
│                  │
│                  ▼
│             [处理层]
│  ┌───────────────────────┐
│  │ Logstash             │
│  │ Fluentd             │
│  │ 数据清洗与转换      │
│  └───────────────────────┘
│                  │
│                  ▼
│             [存储层]
│  ┌───────────────────────┐
│  │ Elasticsearch        │
│  │ ClickHouse          │
│  │ S3 / HDFS          │
│  └───────────────────────┘
```

---

### 2️⃣ Syslog 协议

#### 2.1 Syslog 概述

**Syslog** 是一种标准的日志传输协议，用于在网络中传输日志消息。

| 协议版本 | 特点 | 使用场景 |
|---------|------|---------|
| **RFC 3164 (BSD Syslog)** | 旧版、简单 | 传统 Unix 系统 |
| **RFC 5424 (Syslog RFC)** | 新版、结构化 | 现代系统、结构化日志 |

---

#### 2.2 Syslog 消息格式（RFC 3164）

```
<优先级>时间戳 主机名 标签[进程ID]: 消息
```

**示例**：

```
<34>Jan 22 10:30:00 web-01 nginx[12345]: User admin logged in
```

**优先级计算**：

```
优先级 = 设备编号 × 8 + 严重级别

设备编号（Facility）:
  0 - kern      内核
  1 - user      用户进程
  2 - mail      邮件系统
  3 - daemon    守护进程
  ...
  16-23 - local0-7  本地使用

严重级别（Severity）:
  0 - emerg     紧急
  1 - alert     告警
  2 - crit      严重
  3 - err       错误
  4 - warning   警告
  5 - notice    通知
  6 - info      信息
  7 - debug     调试
```

**示例**：`<34>` = `kern(0) × 8 + notice(5) = 5`（实际上34对应的是 local0(16) × 8 + notice(2) = 130）

---

#### 2.3 Syslog 消息格式（RFC 5424）

```
<优先级>版本 时间戳 主机名 应用 进程ID 消息ID 结构化数据 消息
```

**示例**：

```
<34>1 2026-01-22T10:30:00.123Z web-01 nginx 12345 - [user="admin"] User admin logged in
```

---

#### 2.4 Syslog 传输方式

| 传输方式 | 协议 | 端口 | 优点 | 缺点 |
|---------|------|------|------|------|
| **UDP** | UDP | 514 | 快速、无连接 | 可能丢包、无确认 |
| **TCP** | TCP | 601 | 可靠、有序 | 稍慢 |
| **TLS** | TCP over TLS | 6514 | 加密传输 | 需要证书配置 |

---

### 3️⃣ Filebeat 采集配置

#### 3.1 Filebeat 简介

**Filebeat** 是 Elastic Stack 的轻量级日志采集器，特点：

- 轻量级（低 CPU/内存占用）
- 支持多种输入（文件、容器、系统日志）
- 自动文件发现和轮转检测
- 内置模块（Nginx、Apache、MySQL 等）

---

#### 3.2 Filebeat 配置基础

**配置文件**：`/etc/filebeat/filebeat.yml`

```yaml
# Filebeat 配置示例

filebeat.inputs:
  # 采集 Nginx 访问日志
  - type: log
    enabled: true
    paths:
      - /var/log/nginx/access.log
    fields:
      service: nginx
      log_type: access
    fields_under_root: true
    multiline.pattern: '^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}'
    multiline.negate: true
    multiline.match: after

  # 采集系统日志
  - type: syslog
    enabled: true
    paths:
      - /var/log/syslog
      - /var/log/messages
    fields:
      service: system
      log_type: system

  # 采集应用日志
  - type: log
    enabled: true
    paths:
      - /var/log/myapp/*.log
    fields:
      service: myapp
      log_type: application

# 输出到 Elasticsearch
output.elasticsearch:
  hosts: ["http://elasticsearch:9200"]
  index: "logs-%{+yyyy.MM.dd}"
  
# 输出到 Logstash（替代方案）
# output.logstash:
#   hosts: ["logstash:5044"]

# 处理器
processors:
  # 添加主机名
  - add_host_metadata: ~
  
  # 添加 Cloud 元数据（如果在云上）
  - add_cloud_metadata: ~
  
  # 解析 User Agent
  - user_agent:
      when:
        contains:
          http.user_agent: "Mozilla"
      target: http.user_agent

# 日志级别配置
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

---

#### 3.3 Filebeat 模块配置

Filebeat 内置了常见服务的模块，简化配置。

**Nginx 模块**：

```bash
# 启用 Nginx 模块
filebeat modules enable nginx
```

**配置**：`/etc/filebeat/modules.d/nginx.yml`

```yaml
- module: nginx
  access:
    enabled: true
    var.paths: ["/var/log/nginx/access.log"]
  
  error:
    enabled: true
    var.paths: ["/var/log/nginx/error.log"]
```

---

### 4️⃣ 缓冲与重试策略

#### 4.1 为什么需要缓冲与重试？

**问题场景**：

```
日志流：1000 条/秒
网络带宽：仅支持 500 条/秒

结果：日志积压、丢包
```

**解决方案**：

| 问题 | 缓冲 | 重试 |
|------|------|------|
| 网络中断 | ✅ 保存到本地队列 | ✅ 网络恢复后重试 |
| 目标不可达 | ✅ 积累待发送数据 | ✅ 定期重试连接 |
| 性能抖动 | ✅ 平滑流量 | ✅ 失败后指数退避重试 |

---

#### 4.2 Filebeat 缓冲配置

```yaml
# 内存缓冲
queue.mem:
  events: 4096
  flush.min_events: 512
  flush.timeout: 1s

# 磁盘缓冲（spool）
queue.spool:
  path: ${path.data}/spool-data
  size: 512MB
  page_size: 16KB

# 输出重试
output.elasticsearch:
  hosts: ["http://elasticsearch:9200"]
  
  # 重试次数
  max_retries: 3
  
  # 重试间隔
  retry_on_conflict: default
  backoff.init: 1s
  backoff.max: 60s
  
  # 批量发送
  bulk_max_size: 50
  worker: 1
  
  # 压缩
  compression_level: 3
```

---

#### 4.3 重试策略类型

| 策略 | 描述 | 适用场景 |
|------|------|---------|
| **立即重试** | 失败后立即重试 | 网络抖动 |
| **固定间隔** | 每次重试间隔固定 | 目标短暂不可用 |
| **指数退避** | 间隔逐渐增加（1s, 2s, 4s, 8s...）| 避免雪崩效应 |
| **抖动** | 在指数退避基础上加随机值 | 多客户端并发重试 |

**指数退避示例**：

```
尝试 1: 1s 后重试
尝试 2: 2s 后重试
尝试 3: 4s 后重试
尝试 4: 8s 后重试
尝试 5: 16s 后重试
...
```

---

### 5️⃣ 日志过滤

#### 5.1 过滤的作用

- **减少数据量**：只传输有价值的信息
- **降低存储成本**：过滤掉不需要的日志
- **提高分析效率**：减少无关数据干扰

---

#### 5.2 Filebeat 过滤配置

**drop_event：丢弃事件**

```yaml
processors:
  # 丢弃 health check 日志
  - drop_event:
      when:
        regexp:
          message: "^/health$"
  
  # 丢弃来自特定 IP 的日志
  - drop_event:
      when:
        equals:
          source.ip: "192.168.1.100"
```

**drop_fields：删除字段**

```yaml
processors:
  # 删除敏感字段
  - drop_fields:
      fields: ["password", "credit_card", "ssn"]
      ignore_missing: true
```

**include_fields：只保留指定字段**

```yaml
processors:
  # 只保留关键字段
  - include_fields:
      fields: ["timestamp", "level", "message", "user_id"]
```

**脚本处理**

```yaml
processors:
  # 使用脚本处理
  - script:
      lang: javascript
      id: my_filter
      source: >
        function process(event) {
          // 过滤低级日志
          if (event.level == 'DEBUG') {
            return drop_event();
          }
          return event;
        }
```

---

#### 5.3 Logstash 过滤

**grok 解析**

```ruby
filter {
  grok {
    match => { "message" => "%{COMBINEDAPACHELOG}" }
  }
}
```

**条件过滤**

```ruby
filter {
  # 只保留 ERROR 级别
  if [level] == "ERROR" {
    drop { }
  }
  
  # 过滤健康检查
  if [path] == "/health" {
    drop { }
  }
}
```

**字段修改**

```ruby
filter {
  # 添加字段
  mutate {
    add_field => { "environment" => "production" }
  }
  
  # 重命名字段
  mutate {
    rename => { "host" => "hostname" }
  }
  
  # 转换字段类型
  mutate {
    convert => { "response_size" => "integer" }
  }
}
```

---

## 实践任务（合法授权范围内）

> **注意**：请在你自己的测试环境或虚拟机中执行以下任务。

---

### 任务 1（必做）：安装 Filebeat

**目标**：在本地系统安装 Filebeat。

**步骤**：

**Linux (Ubuntu/Debian）**：

```bash
# 下载并安装
wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.11.0-amd64.deb
sudo dpkg -i filebeat-8.11.0-amd64.deb

# 启用服务
sudo systemctl enable filebeat
sudo systemctl start filebeat

# 检查状态
sudo systemctl status filebeat
```

**Linux (CentOS/RHEL）**：

```bash
# 下载并安装
wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.11.0-x86_64.rpm
sudo rpm -vi filebeat-8.11.0-x86_64.rpm

# 启用服务
sudo systemctl enable filebeat
sudo systemctl start filebeat
```

**验证安装**：

```bash
# 检查版本
filebeat version

# 测试配置
filebeat test config
```

---

### 任务 2（必做）：配置 Filebeat 采集本地日志

**目标**：配置 Filebeat 采集 Nginx 访问日志和系统日志。

**步骤**：

1. **备份原配置**

```bash
sudo cp /etc/filebeat/filebeat.yml /etc/filebeat/filebeat.yml.backup
```

2. **修改配置**

编辑 `/etc/filebeat/filebeat.yml`：

```yaml
filebeat.inputs:
  # Nginx 访问日志
  - type: log
    enabled: true
    paths:
      - /var/log/nginx/access.log
    fields:
      service: nginx
      log_type: access
      environment: lab
    fields_under_root: true
    # 多行处理（如果日志跨多行）
    # multiline.pattern: '^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}'
    # multiline.negate: true
    # multiline.match: after

  # 系统日志
  - type: syslog
    enabled: true
    paths:
      - /var/log/syslog
    fields:
      service: system
      log_type: syslog
      environment: lab

  # Filebeat 自身日志
  - type: log
    enabled: true
    paths:
      - /var/log/filebeat/filebeat
    fields:
      service: filebeat
      log_type: internal

# 输出到控制台（用于测试）
output.console:
  pretty: true

# 输出到 Elasticsearch（稍后配置）
# output.elasticsearch:
#   hosts: ["http://localhost:9200"]

# 处理器
processors:
  - add_host_metadata: ~
  - add_cloud_metadata: ~

# 日志配置
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
```

3. **测试配置**

```bash
# 测试配置文件
sudo filebeat test config

# 测试输出（连接目标）
sudo filebeat test output
```

---

### 任务 3（必做）：测试本地日志采集

**目标**：启动 Filebeat 并验证日志采集。

**步骤**：

1. **启动 Filebeat**

```bash
# 前台运行（查看输出）
sudo filebeat -c /etc/filebeat/filebeat.yml -e

# 或后台运行
sudo systemctl restart filebeat
```

2. **生成测试日志**

```bash
# 访问 Nginx 生成日志
curl http://localhost/
curl http://localhost/api/users
curl http://localhost/notfound

# 写入系统日志
logger "This is a test message from Day030"
logger -t myapp "Application log message"
```

3. **查看 Filebeat 输出**（如果使用 console 输出）

Filebeat 前台运行会显示采集到的日志事件：

```json
{
  "@timestamp": "2026-01-23T10:30:00.123Z",
  "@metadata": {
    "beat": "filebeat",
    "type": "log",
    "version": "8.11.0"
  },
  "service": "nginx",
  "log_type": "access",
  "environment": "lab",
  "message": "192.168.1.10 - - [23/Jan/2026:10:30:00 +0800] \"GET / HTTP/1.1\" 200 1234 \"-\" \"Mozilla/5.0\"",
  "prospector": {
    "type": "log"
  },
  "input": {
    "type": "log"
  }
}
```

---

### 任务 4（必做）：配置日志转发

**目标**：配置 Filebeat 将日志转发到 Elasticsearch 或 Logstash。

**步骤**：

**选项 A：转发到 Elasticsearch**

```yaml
output.elasticsearch:
  hosts: ["http://localhost:9200"]
  index: "logs-%{+yyyy.MM.dd}"
  
  # 认证（如果需要）
  # username: "elastic"
  # password: "changeme"
  
  # SSL 配置（如果使用 HTTPS）
  # protocol: "https"
  # ssl.enabled: true
  # ssl.certificate_authorities: ["/etc/filebeat/ca.crt"]
```

**选项 B：转发到 Logstash**

```yaml
output.logstash:
  hosts: ["localhost:5044"]
  # SSL 配置
  # ssl.enabled: true
  # ssl.certificate_authorities: ["/etc/filebeat/ca.crt"]
```

**选项 C：转发到 Syslog**

```yaml
output.syslog:
  enabled: true
  host: ["localhost"]
  port: 514
  protocol: udp
```

**重启 Filebeat**

```bash
sudo systemctl restart filebeat
sudo systemctl status filebeat
```

---

### 任务 5（必做）：验证端到端日志传输

**目标**：验证日志从采集到存储的完整流程。

**步骤**：

**1. 生成测试日志**

```bash
# 生成 Nginx 访问日志
for i in {1..10}; do
  curl http://localhost/test${i}
  sleep 0.1
done

# 生成系统日志
for i in {1..5}; do
  logger "Test message number ${i} from Day030"
  sleep 0.1
done
```

**2. 在 Elasticsearch 查询**

```bash
# 查询最近的日志
curl -X GET "localhost:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {"@timestamp": "desc"}
  ],
  "size": 20
}'

# 筛选特定服务
curl -X GET "localhost:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "term": {
      "service": "nginx"
    }
  }
}'
```

**3. 在 Kibana 查看日志**

- 打开 Kibana: `http://localhost:5601`
- 进入 Discover 页面
- 选择索引模式：`logs-*`
- 验证日志是否显示

---

### 任务 6（进阶）：配置缓冲与重试

**目标**：为 Filebeat 配置缓冲和重试策略。

**步骤**：

编辑 `/etc/filebeat/filebeat.yml`：

```yaml
# 内存队列
queue.mem:
  events: 4096
  flush.min_events: 512
  flush.timeout: 1s

# 磁盘 Spool（持久化队列）
queue.spool:
  path: ${path.data}/spool-data
  size: 512MB
  page_size: 16KB

# 输出到 Elasticsearch（含重试配置）
output.elasticsearch:
  hosts: ["http://elasticsearch:9200"]
  index: "logs-%{+yyyy.MM.dd}"
  
  # 连接配置
  protocol: "http"
  timeout: 30
  max_retries: 3
  
  # 重试策略（指数退避）
  retry_on_conflict: default
  backoff.init: 1s
  backoff.max: 60s
  
  # 批量发送
  bulk_max_size: 50
  worker: 1
  
  # 压缩
  compression_level: 3
```

**测试重试**：

```bash
# 停止 Elasticsearch 模拟目标不可用
sudo systemctl stop elasticsearch

# 启动 Filebeat
sudo systemctl restart filebeat

# 生成日志
logger "Test message during Elasticsearch downtime"

# 查看 Filebeat 日志，观察重试
sudo tail -f /var/log/filebeat/filebeat

# 重新启动 Elasticsearch
sudo systemctl start elasticsearch

# 验证日志是否发送成功
curl -X GET "localhost:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match": {
      "message": "during Elasticsearch downtime"
    }
  }
}'
```

---

### 任务 7（进阶）：配置日志过滤

**目标**：在 Filebeat 中添加日志过滤规则。

**步骤**：

编辑 `/etc/filebeat/filebeat.yml`：

```yaml
processors:
  # 添加主机信息
  - add_host_metadata: ~
  
  # 添加云元数据（如果在云上）
  - add_cloud_metadata: ~
  
  # 过滤：丢弃健康检查日志
  - drop_event:
      when:
        regexp:
          message: "^/health$"
  
  # 过滤：丢弃调试级别日志
  - drop_event:
      when:
        regexp:
          level: "DEBUG"
  
  # 字段处理：添加环境标签
  - add_fields:
      target: ''
      fields:
        environment: lab
        datacenter: dc-01
  
  # 解析 User Agent（Nginx 模块）
  - user_agent:
      when:
        contains:
          http.user_agent: "Mozilla"
      target: http.user_agent
  
  # Grok 解析（自定义日志格式）
  - grok:
      when:
        regexp:
          service: "myapp"
      field: message
      patterns:
        - "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:msg}"
  
  # 删除敏感字段
  - drop_fields:
      fields: ["password", "token", "api_key"]
      ignore_missing: true
```

**重启 Filebeat**

```bash
sudo filebeat test config
sudo systemctl restart filebeat
```

**测试过滤**：

```bash
# 生成健康检查日志（应该被过滤）
curl http://localhost/health

# 生成调试日志（应该被过滤）
logger -t myapp -p debug "This debug message should be filtered"

# 生成普通日志（应该保留）
logger -t myapp -p info "This info message should be kept"

# 验证 Elasticsearch 中的日志
curl -X GET "localhost:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {"@timestamp": "desc"}
  ]
}'
```

---

## 巩固练习（题与复盘）

---

### 练习 1：传输失败如何兜底？

**思路提示**：

- 本地缓冲（内存队列、磁盘 Spool）
- 重试策略（指数退避、抖动）
- 告警通知（长时间失败触发告警）

---

### 练习 2：加入简单的过滤规则

**任务**：为 Filebeat 添加以下过滤规则：

1. 丢弃来自特定 IP 的日志（如 `192.168.1.100`）
2. 只保留 ERROR 级别及以上的日志
3. 删除敏感字段（password, credit_card, ssn）

---

### 练习 3：配置 Syslog 输出

**任务**：将 Filebeat 配置为输出到 Syslog 服务器。

**思路提示**：

- 配置 `output.syslog`
- 指定目标主机和端口
- 选择传输协议（UDP/TCP）

---

### 练习 4：监控 Filebeat 健康状态

**任务**：编写脚本监控 Filebeat 的状态。

**思路提示**：

- 检查 Filebeat 服务状态
- 检查日志文件大小和增长率
- 检查队列积压情况
- 发送告警（邮件/Slack）

**示例脚本**：

```bash
#!/bin/bash
# Filebeat 健康检查脚本

# 检查服务状态
if ! systemctl is-active --quiet filebeat; then
  echo "WARNING: Filebeat 服务未运行"
  # 发送告警
  exit 1
fi

# 检查日志文件
log_file="/var/log/filebeat/filebeat"
if [ -f "$log_file" ]; then
  size=$(du -m "$log_file" | cut -f1)
  if [ $size -gt 100 ]; then
    echo "WARNING: Filebeat 日志文件过大 (${size} MB)"
  fi
fi

echo "Filebeat 健康检查通过"
```

---

## 评估标准（达成判定）

- ✅ 成功安装并启动 Filebeat
- ✅ 配置了 Filebeat 采集本地日志
- ✅ 验证了日志采集功能（控制台输出或转发）
- ✅ 完成了端到端日志传输验证
- ✅ 配置了缓冲和重试策略
- ✅ 实现了基本的日志过滤规则
- ✅ 提交了配置文件和验证截图

---

## 学习成果达成情况（由学习者填写）

---

### 截图与证据

- [ ] Filebeat 安装成功截图
- [ ] Filebeat 配置文件（filebeat.yml）
- [ ] Filebeat 测试配置输出
- [ ] Filebeat 前台运行日志采集输出
- [ ] Elasticsearch 查询结果截图
- [ ] Kibana 日志查看截图
- [ ] 过滤测试截图

---

### 关键命令与输出（粘贴关键片段）

**安装 Filebeat**：

```bash
$ sudo dpkg -i filebeat-8.11.0-amd64.deb
$ filebeat version
filebeat version 8.11.0 (amd64), libbeat 8.11.0
```

**测试配置**：

```bash
$ sudo filebeat test config
Config OK
```

**启动 Filebeat**：

```bash
$ sudo systemctl restart filebeat
$ sudo systemctl status filebeat
● filebeat.service - Filebeat is a lightweight shipper for log data.
   Loaded: loaded (/lib/systemd/system/filebeat.service; enabled)
   Active: active (running) since Mon 2026-01-23 10:30:00 CST
```

**查看 Filebeat 日志**：

```bash
$ sudo tail -20 /var/log/filebeat/filebeat
2026-01-23T10:30:00.123Z INFO [monitoring] log referenced files...
2026-01-23T10:30:00.456Z INFO [input] No new log files.
2026-01-23T10:30:01.789Z INFO [input] Harvester started for log file: /var/log/nginx/access.log
2026-01-23T10:30:02.345Z INFO [output] Connection to http://localhost:9200/ established
```

**生成测试日志**：

```bash
$ curl http://localhost/
$ logger "Test message from Day030"
```

**查询 Elasticsearch**：

```bash
$ curl -X GET "localhost:9200/logs-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match_all": {}
  },
  "size": 5
}'
```

**查询结果**：

```json
{
  "took": 2,
  "hits": {
    "total": 12,
    "hits": [
      {
        "_source": {
          "@timestamp": "2026-01-23T10:30:01.123Z",
          "service": "nginx",
          "log_type": "access",
          "message": "192.168.1.10 - - [23/Jan/2026:10:30:01 +0800] \"GET / HTTP/1.1\" 200 1234",
          "host": {
            "name": "web-01"
          }
        }
      }
    ]
  }
}
```

---

### 结论与反思

**我今天搞清楚了**：

- 日志收集与传输的完整链路（采集→传输→缓冲→处理→存储）
- Syslog 协议的基本格式和传输方式
- Filebeat 的安装和配置方法
- 日志缓冲和重试策略的重要性
- 基本日志过滤规则的作用

**我差点搞混的是**：

- 最初不理解 Syslog 的优先级计算方法
- 混淆了 Filebeat 的内存队列和磁盘 Spool 的区别
- 不清楚何时使用 UDP vs TCP 传输 Syslog

**明天我要继续补的是**：

- 学习 Elasticsearch/Kibana 的使用（Day031）
- 了解日志告警规则的设计与配置（Day032）
- 学习日志检索与可视化（Day033）

**本次学习耗时**：约 3.5 小时

**掌握程度自评**：

- [ ] 😕 理解了基本概念，但实践不熟练
- [ ] 🙂 完成了 Filebeat 安装和基础配置
- [ ] 😃 完成了所有任务并理解原理
- [ ] 🤩 额外实现了高级过滤和监控脚本

---

## 集中参考答案（含思路）

---

### 练习 1 参考答案：传输失败如何兜底？

**传输失败的兜底策略**：

```
兜底策略层次
│
├─ 第 1 层：本地缓冲
│  ├─ 内存队列（快速缓存）
│  └─ 磁盘 Spool（持久化）
│
├─ 第 2 层：自动重试
│  ├─ 立即重试（网络抖动）
│  ├─ 指数退避（目标不可用）
│  └─ 抖动重试（避免并发雪崩）
│
├─ 第 3 层：告警通知
│  ├─ 服务状态告警
│  ├─ 队列积压告警
│  └─ 长时间失败告警
│
└─ 第 4 层：手动介入
   ├─ 检查网络连接
   ├─ 检查目标服务状态
   └─ 临时切换传输方式
```

---

### 练习 2 参考答案：加入简单的过滤规则

**Filebeat 过滤配置**：

```yaml
processors:
  # 1. 丢弃来自特定 IP 的日志
  - drop_event:
      when:
        equals:
          source.ip: "192.168.1.100"
  
  # 2. 只保留 ERROR 级别及以上的日志
  - drop_event:
      when:
        or:
          - equals:
              level: "DEBUG"
          - equals:
              level: "INFO"
          - equals:
              level: "WARNING"
  
  # 3. 删除敏感字段
  - drop_fields:
      fields: ["password", "credit_card", "ssn", "token"]
      ignore_missing: true
  
  # 4. 添加环境标签
  - add_fields:
      target: ''
      fields:
        environment: lab
        datacenter: dc-01
        project: day030-learning
```

---

### 练习 3 参考答案：配置 Syslog 输出

**Filebeat Syslog 配置**：

```yaml
# 采集日志
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/log/myapp/*.log
    fields:
      service: myapp

# 输出到 Syslog
output.syslog:
  enabled: true
  host: ["syslog-server"]
  port: 514
  
  # 传输协议
  protocol: udp  # 或 tcp
  
  # 使用 RFC 5424 格式
  rfc: "5424"
  
  # 应用名称
  appname: "filebeat"
  
  # 添加字段
  facility: "daemon"
  severity: "information"
  
  # 使用 TLS 加密（TCP only）
  # ssl.enabled: true
  # ssl.certificate_authorities: ["/etc/filebeat/ca.crt"]
  # ssl.certificate: "/etc/filebeat/client.crt"
  # ssl.key: "/etc/filebeat/client.key"
```

**Syslog 服务器接收配置（使用 rsyslog）**：

```conf
# /etc/rsyslog.conf

# 开启 UDP 接收
$ModLoad imudp
$UDPServerRun 514

# 开启 TCP 接收
$ModLoad imtcp
$InputTCPServerRun 514

# 存储到文件
$template FileFormat,"%timegenerated% %HOSTNAME% %syslogtag%%msg%\n"
*.* ?FileLog /var/log/remote_syslog.log;FileFormat
```

---

### 练习 4 参考答案：监控 Filebeat 健康状态

**监控脚本**：

```bash
#!/bin/bash
# Filebeat 健康监控脚本

LOG_FILE="/var/log/filebeat/filebeat"
SPOOL_DIR="/var/lib/filebeat/spool-data"
ALERT_EMAIL="admin@example.com"
ALERT_WEBHOOK="https://hooks.slack.com/services/YOUR/WEBHOOK"

# 检查服务状态
check_service() {
    if ! systemctl is-active --quiet filebeat; then
        send_alert "Filebeat 服务未运行！"
        return 1
    fi
    return 0
}

# 检查日志文件
check_log_file() {
    if [ ! -f "$LOG_FILE" ]; then
        send_alert "Filebeat 日志文件不存在！"
        return 1
    fi
    
    # 检查日志文件大小（MB）
    size_mb=$(du -m "$LOG_FILE" | cut -f1)
    if [ $size_mb -gt 100 ]; then
        send_alert "Filebeat 日志文件过大：${size_mb} MB"
        return 1
    fi
    
    return 0
}

# 检查队列积压
check_spool() {
    if [ ! -d "$SPOOL_DIR" ]; then
        return 0
    fi
    
    # 计算积压文件数量
    spool_count=$(find "$SPOOL_DIR" -type f 2>/dev/null | wc -l)
    
    if [ $spool_count -gt 1000 ]; then
        send_alert "Filebeat 队列积压严重：${spool_count} 个文件"
        return 1
    elif [ $spool_count -gt 100 ]; then
        echo "WARNING: Filebeat 队列积压：${spool_count} 个文件"
    fi
    
    return 0
}

# 检查最近错误
check_errors() {
    # 查看最近 100 行的错误
    error_count=$(tail -100 "$LOG_FILE" | grep -c "ERROR" 2>/dev/null)
    
    if [ $error_count -gt 10 ]; then
        send_alert "Filebeat 最近出现大量错误：${error_count} 个"
        return 1
    fi
    
    return 0
}

# 发送告警
send_alert() {
    message="$1"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $message"
    
    # 发送邮件
    echo "$message" | mail -s "Filebeat Alert" "$ALERT_EMAIL"
    
    # 发送 Slack Webhook
    curl -X POST -H 'Content-Type: application/json' "$ALERT_WEBHOOK" -d '
    {
        "text": "'"$message"'"
    }'
}

# 主检查函数
main() {
    errors=0
    
    check_service || errors=$((errors + 1))
    check_log_file || errors=$((errors + 1))
    check_spool || errors=$((errors + 1))
    check_errors || errors=$((errors + 1))
    
    if [ $errors -eq 0 ]; then
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] Filebeat 健康检查通过"
    fi
    
    return $errors
}

# 运行主检查
main
exit $?
```

**定时运行**：

```bash
# 添加到 crontab（每 5 分钟检查一次）
*/5 * * * * /path/to/filebeat_health_check.sh >> /var/log/filebeat/health_check.log 2>&1
```

---

## 学习成果示例填写（可照抄）

> 可将"示例"内容替换为你自己的时间与截图文件名。

---

### 截图与证据（示例）

- Filebeat 安装：`images/day030_filebeat_install.png`
- 配置文件：`images/day030_filebeat_config.png`
- 健康检查：`images/day030_health_check.png`
- Elasticsearch 查询：`images/day030_es_query.png`

---

### 关键命令与输出（示例）

**安装 Filebeat**：

```bash
$ sudo dpkg -i filebeat-8.11.0-amd64.deb
$ filebeat version
filebeat version 8.11.0
```

**查询 Elasticsearch**：

```json
{
  "hits": {
    "total": 12,
    "hits": [
      {
        "_source": {
          "service": "nginx",
          "message": "192.168.1.10 - - GET / HTTP/1.1\" 200 1234"
        }
      }
    ]
  }
}
```

---

### 结论与反思（示例）

**我今天搞清楚了**：

- 日志收集与传输的完整链路
- Syslog 协议的基本格式
- Filebeat 的安装和配置
- 缓冲和重试策略的重要性

**我差点搞混的是**：

- Syslog 优先级计算方法
- 内存队列和磁盘 Spool 的区别

**明天我要继续补的是**：

- 学习 Elasticsearch/Kibana 使用
- 了解日志告警规则设计

**本次学习耗时**：约 3.5 小时

**掌握程度自评**：

- [x] 😃 完成了所有任务并理解原理
